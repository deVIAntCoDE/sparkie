REQUIRED
==============
Java8
Spark Built against Scala-2.11

I chose to implement this in a Scala Spark project because i felt the questions were very well suited as a spark use case.
Also i wanted to use this as an opportunity to actually write a spark application since i have never done that. I planned to
try out sparkSql as well but i feel i have spent too much time on this so perhaps i will explore that later on my own time.

Setting up Local Spark
===============================
Download the latest spark project from apache.spark.org
follow the instructions in the README file to build spark for scala 2.11
   -> dev/change-version-to-2.11.sh
   -> mvn -Pyarn -Phadoop-2.4 -Dscala-2.11 -DskipTests clean package

Testing
========
to test run the sbt test command


RUNNING
=================
1. Package the spark application in sbt to get the jar 'sparkie_2.11-1.0.jar'

2. To run the project, execute the code below in the spark home directory. Provide the path to the input data and an output directory as shown below.

 ./bin/spark-submit \
    --class com.hnocleland.Sparkie \
    --master "local[*]" \
    --driver-memory 8G \
    --conf spark.lastfmStats="/path/to/lastfm/userid-timestamp-artid-artname-traid-traname.tsv" \
    /path/to/sparkie_2.11-1.0.jar \
    "/path/to/sparkie_output"

3. After completion, there will be two versions of the output file in the specified output directory for each question:
   merged -> a single file with the result
   parts -> parts files of the result from the different partitions
   Merged are for viewing and the parts can be fed back into other spark jobs for further analysis


#Todo: pass sample file as lastfmstats in spark-submit scrip to test --config isnt broken
#Partition data and try using fold for the playlist comparison to see performance time.